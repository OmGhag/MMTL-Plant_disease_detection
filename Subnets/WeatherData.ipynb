{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55qyTCpmzQJI"
   },
   "source": [
    "### Setting up Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_VVqNFTzUm1"
   },
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaKF17Gh3GYq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "import math\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score\n",
    "import os\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHg4l0Pfy2ju"
   },
   "outputs": [],
   "source": [
    "kaggle_credentials = json.load(open('kaggle.json'))\n",
    "os.environ['KAGGLE_USERNAME'] = kaggle_credentials['username']\n",
    "os.environ['KAGGLE_KEY'] = kaggle_credentials['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15413,
     "status": "ok",
     "timestamp": 1756442997238,
     "user": {
      "displayName": "Om ghag",
      "userId": "00154498288152246240"
     },
     "user_tz": 420
    },
    "id": "k48in-TXzhSn",
    "outputId": "35bb96da-6733-4d42-c002-855ee9447c1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/abdallahalidev/plantvillage-dataset\n",
      "License(s): CC-BY-NC-SA-4.0\n",
      "Downloading plantvillage-dataset.zip to /content\n",
      " 97% 1.98G/2.04G [00:02<00:00, 895MB/s]\n",
      "100% 2.04G/2.04G [00:02<00:00, 969MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d abdallahalidev/plantvillage-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TN3lvh0LzowW"
   },
   "outputs": [],
   "source": [
    "with ZipFile(r'/content/plantvillage-dataset.zip', 'r') as zipObj:\n",
    "   zipObj.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60CwmdFRzsq6"
   },
   "outputs": [],
   "source": [
    "base_dir = r'/content/plantvillage dataset/color'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GeE336E0DpJ"
   },
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAnCW8UG1McS"
   },
   "outputs": [],
   "source": [
    "Data_Gen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1756443028345,
     "user": {
      "displayName": "Om ghag",
      "userId": "00154498288152246240"
     },
     "user_tz": 420
    },
    "id": "-0NJfQ-Y1Tyj",
    "outputId": "b35ddefc-8b42-4f0d-9fda-aadbea96a364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43456 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = Data_Gen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size = (img_size, img_size),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'training',\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 580,
     "status": "ok",
     "timestamp": 1756443028928,
     "user": {
      "displayName": "Om ghag",
      "userId": "00154498288152246240"
     },
     "user_tz": 420
    },
    "id": "wU2RTwlO1bOv",
    "outputId": "91cb2e2b-e1d1-4406-fe84-c73f67fb52a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10849 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = Data_Gen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size = (img_size, img_size),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'validation',\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Il2_N3DZ1hZ8"
   },
   "outputs": [],
   "source": [
    "#Create a mapping from class indices to class names\n",
    "class_indices = {v: k for k, v in train_generator.class_indices.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-eQx3zj1_OF"
   },
   "source": [
    "#### Weather data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGOS_cV6Ipui"
   },
   "outputs": [],
   "source": [
    "# ---------- 1) disease list (user-provided) ----------\n",
    "DISEASE_LIST = [\n",
    "  'Apple___Apple_scab','Apple___Black_rot','Apple___Cedar_apple_rust','Apple___healthy',\n",
    "  'Blueberry___healthy','Cherry_(including_sour)___Powdery_mildew','Cherry_(including_sour)___healthy',\n",
    "  'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot','Corn_(maize)___Common_rust_','Corn_(maize)___Northern_Leaf_Blight',\n",
    "  'Corn_(maize)___healthy','Grape___Black_rot','Grape___Esca_(Black_Measles)','Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
    "  'Grape___healthy','Orange___Haunglongbing_(Citrus_greening)','Peach___Bacterial_spot','Peach___healthy',\n",
    "  'Pepper,_bell___Bacterial_spot','Pepper,_bell___healthy','Potato___Early_blight','Potato___Late_blight',\n",
    "  'Potato___healthy','Raspberry___healthy','Soybean___healthy','Squash___Powdery_mildew','Strawberry___Leaf_scorch',\n",
    "  'Strawberry___healthy','Tomato___Bacterial_spot','Tomato___Early_blight','Tomato___Late_blight','Tomato___Leaf_Mold',\n",
    "  'Tomato___Septoria_leaf_spot','Tomato___Spider_mites Two-spotted_spider_mite','Tomato___Target_Spot',\n",
    "  'Tomato___Tomato_Yellow_Leaf_Curl_Virus','Tomato___Tomato_mosaic_virus','Tomato___healthy'\n",
    "]\n",
    "DISEASE_TO_ID = {name: i for i, name in enumerate(DISEASE_LIST)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9Zzg_As2qQa"
   },
   "outputs": [],
   "source": [
    "def parse_disease_name(disease_name):\n",
    "    \"\"\"Extract plant type and disease type from disease name\"\"\"\n",
    "    parts = disease_name.split('___')\n",
    "    if len(parts) == 2:\n",
    "        plant_type = parts[0].strip()\n",
    "        disease_type = parts[1].strip()\n",
    "        return plant_type, disease_type\n",
    "    return disease_name, \"unknown\"\n",
    "\n",
    "# Base weather profiles for each plant type (healthy growing conditions)\n",
    "BASE_PLANT_PROFILES = {\n",
    "    'Apple': {\n",
    "        'temp_range': (18, 24),         # °C - optimal growing range\n",
    "        'humidity_base': 65,            # % - moderate humidity\n",
    "        'soil_moisture_target': 0.25,   # m3/m3 - well-drained but moist\n",
    "        'temp_tolerance': 3,            # °C - temperature variation tolerance\n",
    "    },\n",
    "    'Tomato': {\n",
    "        'temp_range': (20, 26),\n",
    "        'humidity_base': 70,\n",
    "        'soil_moisture_target': 0.30,\n",
    "        'temp_tolerance': 2,\n",
    "    },\n",
    "    'Corn_(maize)': {\n",
    "        'temp_range': (22, 28),\n",
    "        'humidity_base': 60,\n",
    "        'soil_moisture_target': 0.35,\n",
    "        'temp_tolerance': 4,\n",
    "    },\n",
    "    'Potato': {\n",
    "        'temp_range': (16, 22),\n",
    "        'humidity_base': 75,\n",
    "        'soil_moisture_target': 0.28,\n",
    "        'temp_tolerance': 2,\n",
    "    },\n",
    "    'Grape': {\n",
    "        'temp_range': (20, 25),\n",
    "        'humidity_base': 60,\n",
    "        'soil_moisture_target': 0.20,\n",
    "        'temp_tolerance': 3,\n",
    "    },\n",
    "    'Peach': {\n",
    "        'temp_range': (21, 27),\n",
    "        'humidity_base': 65,\n",
    "        'soil_moisture_target': 0.25,\n",
    "        'temp_tolerance': 3,\n",
    "    },\n",
    "    'Cherry_(including_sour)': {\n",
    "        'temp_range': (18, 24),\n",
    "        'humidity_base': 68,\n",
    "        'soil_moisture_target': 0.22,\n",
    "        'temp_tolerance': 3,\n",
    "    },\n",
    "    'Strawberry': {\n",
    "        'temp_range': (18, 24),\n",
    "        'humidity_base': 70,\n",
    "        'soil_moisture_target': 0.30,\n",
    "        'temp_tolerance': 2,\n",
    "    },\n",
    "    'Pepper,_bell': {\n",
    "        'temp_range': (21, 27),\n",
    "        'humidity_base': 65,\n",
    "        'soil_moisture_target': 0.28,\n",
    "        'temp_tolerance': 2,\n",
    "    },\n",
    "    'Squash': {\n",
    "        'temp_range': (20, 26),\n",
    "        'humidity_base': 70,\n",
    "        'soil_moisture_target': 0.32,\n",
    "        'temp_tolerance': 3,\n",
    "    },\n",
    "    'Orange': {\n",
    "        'temp_range': (24, 30),\n",
    "        'humidity_base': 60,\n",
    "        'soil_moisture_target': 0.25,\n",
    "        'temp_tolerance': 4,\n",
    "    },\n",
    "    'Soybean': {\n",
    "        'temp_range': (22, 28),\n",
    "        'humidity_base': 65,\n",
    "        'soil_moisture_target': 0.30,\n",
    "        'temp_tolerance': 3,\n",
    "    },\n",
    "    'Raspberry': {\n",
    "        'temp_range': (18, 23),\n",
    "        'humidity_base': 72,\n",
    "        'soil_moisture_target': 0.28,\n",
    "        'temp_tolerance': 2,\n",
    "    },\n",
    "    'Blueberry': {\n",
    "        'temp_range': (16, 22),\n",
    "        'humidity_base': 75,\n",
    "        'soil_moisture_target': 0.35,\n",
    "        'temp_tolerance': 2,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Disease modification rules (pathogen-friendly modifications)\n",
    "DISEASE_MODIFICATIONS = {\n",
    "    'healthy': {\n",
    "        # No modifications - use base profile\n",
    "        'humidity_shift': 0,\n",
    "        'temp_stress_factor': 1.0,\n",
    "        'moisture_shift': 0,\n",
    "        'leaf_wetness_boost': 0,\n",
    "    },\n",
    "    # Fungal diseases - love moisture and moderate temps\n",
    "    'blight': {\n",
    "        'humidity_shift': +8,           # Higher humidity\n",
    "        'temp_stress_factor': 0.8,     # More temperature variation (stress)\n",
    "        'moisture_shift': +0.08,       # More soil moisture\n",
    "        'leaf_wetness_boost': +6,      # More leaf wetness hours\n",
    "    },\n",
    "    'rust': {\n",
    "        'humidity_shift': +10,\n",
    "        'temp_stress_factor': 0.7,\n",
    "        'moisture_shift': +0.06,\n",
    "        'leaf_wetness_boost': +8,\n",
    "    },\n",
    "    'rot': {\n",
    "        'humidity_shift': +12,\n",
    "        'temp_stress_factor': 0.6,\n",
    "        'moisture_shift': +0.10,\n",
    "        'leaf_wetness_boost': +10,\n",
    "    },\n",
    "    'scab': {\n",
    "        'humidity_shift': +6,\n",
    "        'temp_stress_factor': 0.8,\n",
    "        'moisture_shift': +0.05,\n",
    "        'leaf_wetness_boost': +5,\n",
    "    },\n",
    "    'mildew': {\n",
    "        'humidity_shift': +15,\n",
    "        'temp_stress_factor': 0.7,\n",
    "        'moisture_shift': +0.08,\n",
    "        'leaf_wetness_boost': +12,\n",
    "    },\n",
    "    # Bacterial diseases - also like moisture but different patterns\n",
    "    'spot': {\n",
    "        'humidity_shift': +5,\n",
    "        'temp_stress_factor': 0.9,\n",
    "        'moisture_shift': +0.04,\n",
    "        'leaf_wetness_boost': +4,\n",
    "    },\n",
    "    # Viral diseases - stress conditions\n",
    "    'virus': {\n",
    "        'humidity_shift': -2,\n",
    "        'temp_stress_factor': 0.5,     # High stress\n",
    "        'moisture_shift': -0.02,\n",
    "        'leaf_wetness_boost': +2,\n",
    "    },\n",
    "    'mosaic': {\n",
    "        'humidity_shift': -3,\n",
    "        'temp_stress_factor': 0.6,\n",
    "        'moisture_shift': -0.03,\n",
    "        'leaf_wetness_boost': +1,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XE7j9efmH7Qf"
   },
   "outputs": [],
   "source": [
    "def get_disease_category(disease_type):\n",
    "    \"\"\"Categorize disease type into modification groups\"\"\"\n",
    "    disease_lower = disease_type.lower()\n",
    "\n",
    "    # Check for specific disease patterns\n",
    "    for category in DISEASE_MODIFICATIONS.keys():\n",
    "        if category in disease_lower:\n",
    "            return category\n",
    "\n",
    "    # Default categorization based on keywords\n",
    "    if any(keyword in disease_lower for keyword in ['blight', 'early_blight', 'late_blight']):\n",
    "        return 'blight'\n",
    "    elif any(keyword in disease_lower for keyword in ['rust', 'cedar_apple_rust', 'common_rust']):\n",
    "        return 'rust'\n",
    "    elif any(keyword in disease_lower for keyword in ['rot', 'black_rot']):\n",
    "        return 'rot'\n",
    "    elif any(keyword in disease_lower for keyword in ['spot', 'bacterial_spot', 'leaf_spot']):\n",
    "        return 'spot'\n",
    "    elif any(keyword in disease_lower for keyword in ['mildew', 'powdery_mildew']):\n",
    "        return 'mildew'\n",
    "    elif any(keyword in disease_lower for keyword in ['virus', 'mosaic']):\n",
    "        return 'virus'\n",
    "    elif 'healthy' in disease_lower:\n",
    "        return 'healthy'\n",
    "    else:\n",
    "        return 'spot'  # Default to bacterial-like conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5slEw7JHpYNG"
   },
   "source": [
    "#### Build the weather generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iS0ieUM22zxs"
   },
   "outputs": [],
   "source": [
    "def build_targeted_hourly_weather(start_dt: datetime, end_dt: datetime,\n",
    "                                 plant_type: str, disease_type: str, seed=42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build hourly weather data tailored to specific plant-disease combinations\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    hours = int((end_dt - start_dt).total_seconds() // 3600)\n",
    "    timestamps = [start_dt + timedelta(hours=i) for i in range(hours)]\n",
    "    hour_of_day = np.array([t.hour for t in timestamps])\n",
    "\n",
    "    # Get base plant profile\n",
    "    plant_profile = BASE_PLANT_PROFILES.get(plant_type, BASE_PLANT_PROFILES['Tomato'])\n",
    "\n",
    "    # Get disease modifications\n",
    "    disease_category = get_disease_category(disease_type)\n",
    "    disease_mods = DISEASE_MODIFICATIONS.get(disease_category, DISEASE_MODIFICATIONS['healthy'])\n",
    "\n",
    "    # Build temperature with plant-specific ranges and disease stress\n",
    "    temp_min, temp_max = plant_profile['temp_range']\n",
    "    temp_center = (temp_min + temp_max) / 2\n",
    "    temp_tolerance = plant_profile['temp_tolerance'] * disease_mods['temp_stress_factor']\n",
    "\n",
    "    # Daily temperature cycle with plant-specific center and disease-induced stress\n",
    "    temp_daily = temp_center + (temp_max - temp_center) * 0.7 * np.sin((hour_of_day - 6) / 24 * 2 * np.pi)\n",
    "    air_temp = temp_daily + np.random.normal(0, temp_tolerance, hours)\n",
    "\n",
    "    # Humidity with plant base + disease modification\n",
    "    target_humidity = plant_profile['humidity_base'] + disease_mods['humidity_shift']\n",
    "    rel_humidity = target_humidity - 0.9 * (air_temp - temp_center) + np.random.normal(0, 4.5, hours)\n",
    "    rel_humidity = np.clip(rel_humidity, 20, 100)\n",
    "\n",
    "    # Precipitation (keep original storm logic but adjust for disease)\n",
    "    precip = np.zeros(hours)\n",
    "    days = max(1, (end_dt - start_dt).days)\n",
    "    n_storms = max(3, days // 7)\n",
    "    if disease_category in ['blight', 'rust', 'rot', 'mildew']:\n",
    "        n_storms = int(n_storms * 1.3)  # More rain events for fungal diseases\n",
    "\n",
    "    storm_centers = np.random.choice(hours, n_storms, replace=False)\n",
    "    for c in storm_centers:\n",
    "        dur = np.random.randint(3, 18)\n",
    "        intens = np.random.uniform(0.5, 20)\n",
    "        end_idx = min(hours, c + dur)\n",
    "        span = np.arange(end_idx - c)\n",
    "        precip[c:end_idx] += intens * np.exp(-0.25 * span)\n",
    "\n",
    "    # Leaf wetness with disease-specific boost\n",
    "    leaf_wetness = np.zeros(hours, dtype=int)\n",
    "    base_wetness_boost = disease_mods['leaf_wetness_boost']\n",
    "    for i in range(hours):\n",
    "        prev24 = precip[max(0, i-24):i+1]\n",
    "        dew = 1 if (rel_humidity[i] > 92 and hour_of_day[i] < 8) else 0\n",
    "        base_wetness = np.sum(prev24 > 0) + dew*3 + np.random.randint(0,3)\n",
    "        leaf_wetness[i] = min(24, int(base_wetness + base_wetness_boost))\n",
    "\n",
    "    # Soil moisture with plant-specific target + disease modification\n",
    "    target_moisture = plant_profile['soil_moisture_target'] + disease_mods['moisture_shift']\n",
    "    soil_moisture = np.zeros(hours)\n",
    "    soil_moisture[0] = target_moisture\n",
    "    for i in range(1, hours):\n",
    "        gain = min(0.18, precip[i] / 60.0) if precip[i] > 0 else 0.\n",
    "        soil_moisture[i] = soil_moisture[i-1] * 0.994 - 0.0007 * max(0, air_temp[i]-temp_center) + gain\n",
    "    soil_moisture = np.clip(soil_moisture, 0.03, 0.6)\n",
    "\n",
    "    # Calculate derived parameters\n",
    "    dew_point = air_temp - (100 - rel_humidity) / 5.0\n",
    "    es = 0.6108 * np.exp(17.27 * air_temp / (air_temp + 237.3))\n",
    "    ea = es * (rel_humidity / 100.0)\n",
    "    vpd = es - ea\n",
    "\n",
    "    wind_speed = np.abs(np.random.normal(2.5, 1.1, hours))\n",
    "    solar = np.maximum(0, 600 * np.sin(np.clip((hour_of_day-6)/12 * np.pi, -np.pi, np.pi))) + np.random.normal(0,25,hours)\n",
    "    solar = np.clip(solar, 0, None)\n",
    "    soil_temp = air_temp * 0.85 + 2 + np.random.normal(0,0.6,hours)\n",
    "    frost_flag = (air_temp < 0).astype(int)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': timestamps,\n",
    "        'air_temp_C': np.round(air_temp,2),\n",
    "        'rel_humidity_%': np.round(rel_humidity,1),\n",
    "        'leaf_wetness_hours_last24': leaf_wetness,\n",
    "        'precip_mm_hr': np.round(precip,3),\n",
    "        'soil_moisture_m3m3': np.round(soil_moisture,4),\n",
    "        'dew_point_C': np.round(dew_point,2),\n",
    "        'vpd_kPa': np.round(vpd,3),\n",
    "        'wind_speed_m_s': np.round(wind_speed,2),\n",
    "        'solar_W_m2': np.round(solar,1),\n",
    "        'soil_temp_C': np.round(soil_temp,2),\n",
    "        'frost_flag': frost_flag\n",
    "    })\n",
    "    df = df.set_index('timestamp')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPZ1BFaU3OaY"
   },
   "outputs": [],
   "source": [
    "def build_targeted_weather_generator(train_generator, window_days=7, seed=42):\n",
    "    \"\"\"\n",
    "    Build weather generator with plant-disease specific weather patterns\n",
    "    \"\"\"\n",
    "    # Get filepaths from image generator\n",
    "    if hasattr(train_generator, 'filepaths'):\n",
    "        all_filepaths = train_generator.filepaths\n",
    "    else:\n",
    "        all_filepaths = [os.path.join(train_generator.directory, f) for f in train_generator.filenames]\n",
    "\n",
    "    # Build DataFrame with plant-disease info\n",
    "    df = pd.DataFrame({'filepath': all_filepaths})\n",
    "    df['disease_name'] = df['filepath'].apply(lambda p: Path(p).parent.name)\n",
    "    df['disease_id'] = df['disease_name'].map(lambda n: DISEASE_TO_ID.get(n, -1))\n",
    "\n",
    "    # Parse plant and disease types\n",
    "    parsed = df['disease_name'].apply(parse_disease_name)\n",
    "    df['plant_type'] = [p[0] for p in parsed]\n",
    "    df['disease_type'] = [p[1] for p in parsed]\n",
    "\n",
    "    # Assign timestamps grouped by plant-disease combination for more realistic patterns\n",
    "    start_date = datetime(2025, 1, 1)\n",
    "    end_date = datetime(2025, 8, 21)\n",
    "    df['timestamp'] = pd.NaT\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    for (plant, disease), g in df.groupby(['plant_type', 'disease_type']):\n",
    "        idx = g.index\n",
    "        n = len(idx)\n",
    "        if n == 0: continue\n",
    "\n",
    "        # Create time clusters for same plant-disease combinations\n",
    "        # This makes weather patterns more realistic within groups\n",
    "        seconds_span = int((end_date - start_date).total_seconds())\n",
    "        cluster_centers = np.random.uniform(0, seconds_span, min(n//10 + 1, 20))\n",
    "\n",
    "        timestamps = []\n",
    "        for i in range(n):\n",
    "            center = np.random.choice(cluster_centers)\n",
    "            jitter = np.random.normal(0, seconds_span * 0.1)  # 10% of total span\n",
    "            timestamp_secs = np.clip(center + jitter, 0, seconds_span)\n",
    "            timestamps.append(start_date + timedelta(seconds=int(timestamp_secs)))\n",
    "\n",
    "        df.loc[idx, 'timestamp'] = timestamps\n",
    "\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    # Precompute targeted weather for each sample\n",
    "    print(\"Generating plant-disease specific weather patterns...\")\n",
    "    precomputed = {}\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        # Generate weather for this specific plant-disease combination\n",
    "        min_ts = row['timestamp'] - timedelta(days=window_days+1)\n",
    "        max_ts = row['timestamp'] + timedelta(days=1)\n",
    "\n",
    "        weather_df = build_targeted_hourly_weather(\n",
    "            min_ts, max_ts,\n",
    "            row['plant_type'], row['disease_type'],\n",
    "            seed=seed+i  # Different seed per sample for variety\n",
    "        )\n",
    "\n",
    "        # Extract time series for this sample\n",
    "        timeseries_data = extract_timeseries_features(\n",
    "            weather_df, row['timestamp'], window_days=window_days\n",
    "        )\n",
    "        precomputed[row['filepath']] = timeseries_data\n",
    "\n",
    "    def targeted_weather_generator():\n",
    "        \"\"\"Generator yielding plant-disease specific weather patterns\"\"\"\n",
    "        train_generator.reset()\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                image_batch, label_batch = next(train_generator)\n",
    "\n",
    "                batch_start = train_generator.batch_index * train_generator.batch_size\n",
    "                batch_end = min(batch_start + train_generator.batch_size, len(all_filepaths))\n",
    "                batch_paths = all_filepaths[batch_start:batch_end]\n",
    "\n",
    "                if len(batch_paths) != len(label_batch):\n",
    "                    batch_paths = batch_paths[:len(label_batch)]\n",
    "\n",
    "                batch_weather = np.stack([precomputed[p] for p in batch_paths], axis=0)\n",
    "                yield batch_weather, label_batch\n",
    "\n",
    "            except StopIteration:\n",
    "                train_generator.reset()\n",
    "                continue\n",
    "\n",
    "    return targeted_weather_generator(), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slqm6XyL3EGV"
   },
   "outputs": [],
   "source": [
    "def extract_timeseries_features(weather_df: pd.DataFrame, end_ts: datetime, window_days: int = 7) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract raw hourly time series data instead of aggregated features.\n",
    "    Returns shape: (timesteps, features)\n",
    "    \"\"\"\n",
    "    W = window_days * 24  # 168 hours for 7 days\n",
    "    start_ts = end_ts - timedelta(hours=W) + timedelta(hours=1)\n",
    "    window = weather_df.loc[start_ts:end_ts]\n",
    "\n",
    "    # Pad if shorter than W hours\n",
    "    if len(window) < W:\n",
    "        pad_n = W - len(window)\n",
    "        # Use first available row for padding\n",
    "        pad_row = weather_df.iloc[0:1].copy()\n",
    "        pads = pd.concat([pad_row]*pad_n, ignore_index=False)\n",
    "        pads.index = [start_ts - timedelta(hours=i+1) for i in range(pad_n)][::-1]\n",
    "        window = pd.concat([pads, window]).sort_index()\n",
    "\n",
    "    # Take only the last W hours to ensure exact length\n",
    "    window = window.tail(W)\n",
    "\n",
    "    # Select the features you want for time series (excluding timestamp)\n",
    "    feature_cols = [\n",
    "        'air_temp_C', 'rel_humidity_%', 'leaf_wetness_hours_last24',\n",
    "        'precip_mm_hr', 'soil_moisture_m3m3', 'dew_point_C',\n",
    "        'vpd_kPa', 'wind_speed_m_s', 'solar_W_m2', 'soil_temp_C', 'frost_flag'\n",
    "    ]\n",
    "\n",
    "    # Convert to numpy array: shape (timesteps, features)\n",
    "    timeseries_data = window[feature_cols].values.astype(np.float32)\n",
    "\n",
    "    return timeseries_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AsO90gFp16_"
   },
   "source": [
    "### Generate Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 360272,
     "status": "ok",
     "timestamp": 1756443389303,
     "user": {
      "displayName": "Om ghag",
      "userId": "00154498288152246240"
     },
     "user_tz": 420
    },
    "id": "wp_MrfiB2yLW",
    "outputId": "867474e0-6602-4c07-efaa-ffe353fea9f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating plant-disease specific weather patterns...\n",
      "Generating plant-disease specific weather patterns...\n"
     ]
    }
   ],
   "source": [
    "w_train_gen, train_image_index_df = build_targeted_weather_generator(train_generator, window_days=7)\n",
    "w_val_gen, val_image_index_df = build_targeted_weather_generator(val_generator, window_days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1756443389425,
     "user": {
      "displayName": "Om ghag",
      "userId": "00154498288152246240"
     },
     "user_tz": 420
    },
    "id": "CPYZdbDF3ath",
    "outputId": "b88c9b3f-d320-40fc-8f56-95b3c26f5d3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather shape: (32, 168, 11)\n",
      "Label shape: (32, 38)\n"
     ]
    }
   ],
   "source": [
    "weather_batch, label_batch = next(w_train_gen)\n",
    "print(\"Weather shape:\", weather_batch.shape)\n",
    "print(\"Label shape:\", label_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1756443389483,
     "user": {
      "displayName": "Om ghag",
      "userId": "00154498288152246240"
     },
     "user_tz": 420
    },
    "id": "3c6b261f",
    "outputId": "de464bd4-a59b-420b-bb23-c219cc7aaa6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather shape: (32, 168, 11)\n",
      "Label shape: (32, 38)\n"
     ]
    }
   ],
   "source": [
    "weather_batch, label_batch = next(w_val_gen)\n",
    "print(\"Weather shape:\", weather_batch.shape)\n",
    "print(\"Label shape:\", label_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "error",
     "timestamp": 1756443389536,
     "user": {
      "displayName": "Om ghag",
      "userId": "00154498288152246240"
     },
     "user_tz": 420
    },
    "id": "6BUccGfVJteo",
    "outputId": "28963e47-afd7-48e9-f324-e51afd450521"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1627848570.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw_train_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_train_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mw_val_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_val_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "w_train_gen = w_train_gen[:,-48,:]\n",
    "w_val_gen = w_val_gen[:,-48,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0YrQDxOJSQB"
   },
   "outputs": [],
   "source": [
    "def build_weather_branch_short_window(self):\n",
    "        \"\"\"Weather model with shorter time window (24-48 hours)\"\"\"\n",
    "        # Shorter window - last 48 hours instead of 168\n",
    "        short_timesteps = 48\n",
    "        input_weather = Input(shape=(short_timesteps, self.n_weather_features), name='weather_short_input')\n",
    "\n",
    "        # Feature normalization\n",
    "        x = layers.Lambda(lambda x: (x - tf.reduce_mean(x, axis=1, keepdims=True)) /\n",
    "                         (tf.math.reduce_std(x, axis=1, keepdims=True) + 1e-8))(input_weather)\n",
    "\n",
    "        # Lighter LSTM architecture\n",
    "        x = layers.LSTM(32, return_sequences=True, dropout=0.3)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.LSTM(16, return_sequences=False, dropout=0.3)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # Compact dense layers\n",
    "        x = layers.Dense(32, activation='relu')(x)\n",
    "        x = layers.Dropout(0.4)(x)\n",
    "\n",
    "        weather_features_short = layers.Dense(32, activation='relu', name='weather_features_short')(x)\n",
    "        weather_pred_short = layers.Dense(self.n_classes, activation='softmax', name='weather_pred_short')(weather_features_short)\n",
    "\n",
    "        return Model(inputs=input_weather, outputs=[weather_features_short, weather_pred_short],\n",
    "                    name='weather_short')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNHM3ecDp6Le"
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "djUxXEP56OB-"
   },
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "def create_improved_weather_model(timesteps=168, n_features=11, n_classes=38):\n",
    "    \"\"\"\n",
    "    Improved weather-based LSTM model with better architecture\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # Input normalization\n",
    "        layers.Input(shape=(timesteps, n_features)),\n",
    "        layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=-1)),  # Feature normalization\n",
    "\n",
    "        # First LSTM layer with more units\n",
    "        layers.LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "        # Second LSTM layer\n",
    "        layers.LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "        # Third LSTM layer\n",
    "        layers.LSTM(32, return_sequences=False, dropout=0.2, recurrent_dropout=0.2),\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "        # Dense layers with residual connections\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        # Output layer\n",
    "        layers.Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Use a lower learning rate and better optimizer\n",
    "    optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "error",
     "timestamp": 1756442944606,
     "user": {
      "displayName": "Om ghag",
      "userId": "00154498288152246240"
     },
     "user_tz": 420
    },
    "id": "9lSUWNnWfthU",
    "outputId": "6e9e8058-735d-4ddb-996c-e6685b2ecb80"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-740079627.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define the number of steps per epoch for training and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This should be the total number of samples divided by the batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msteps_per_epoch_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msteps_per_epoch_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the number of steps per epoch for training and validation\n",
    "# This should be the total number of samples divided by the batch size\n",
    "steps_per_epoch_train = train_generator.samples // train_generator.batch_size\n",
    "steps_per_epoch_val = val_generator.samples // val_generator.batch_size\n",
    "\n",
    "model = build_weather_branch_short_window()\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    w_train_gen,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    epochs=15, # You can adjust the number of epochs\n",
    "    validation_data=w_val_gen,\n",
    "    validation_steps=steps_per_epoch_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dL43fAfTJKR"
   },
   "outputs": [],
   "source": [
    "def create_fixed_weather_model(timesteps=168, n_features=11, n_classes=38):\n",
    "    \"\"\"\n",
    "    Fixed version of your current model with immediate improvements\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "\n",
    "    model = Sequential([\n",
    "        # Input shape: (batch_size, timesteps, features)\n",
    "        Input(shape=(timesteps, n_features)),\n",
    "\n",
    "        # Add feature normalization\n",
    "        Lambda(lambda x: (x - tf.reduce_mean(x, axis=1, keepdims=True)) /\n",
    "                         (tf.math.reduce_std(x, axis=1, keepdims=True) + 1e-8)),\n",
    "\n",
    "        # Simplified architecture - your current one might be too complex\n",
    "        LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.3,\n",
    "             kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        LSTM(32, return_sequences=False, dropout=0.3, recurrent_dropout=0.3,\n",
    "             kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        # Simpler dense layers\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        # Output layer\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Better optimizer settings\n",
    "    optimizer = Adam(learning_rate=0.001, clipnorm=1.0)  # Add gradient clipping\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XECHvHhPm0nH"
   },
   "outputs": [],
   "source": [
    "# Define the number of steps per epoch for training and validation\n",
    "# This should be the total number of samples divided by the batch size\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization, Lambda\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "steps_per_epoch_train = train_generator.samples // train_generator.batch_size\n",
    "steps_per_epoch_val = val_generator.samples // val_generator.batch_size\n",
    "\n",
    "model = create_fixed_weather_model()\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    w_train_gen,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    epochs=15, # You can adjust the number of epochs\n",
    "    validation_data=w_val_gen,\n",
    "    validation_steps=steps_per_epoch_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7ofZIFM7EeF"
   },
   "outputs": [],
   "source": [
    "# Combined Data Generator for Fusion Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_combined_generator(image_gen, weather_gen, soil_x, soil_y, batch_size=32):\n",
    "    \"\"\"\n",
    "    Creates a combined generator that yields (images, weather, soil) data and labels\n",
    "\n",
    "    Args:\n",
    "        image_gen: Keras ImageDataGenerator (train_gen, validation_gen, etc.)\n",
    "        weather_gen: Weather data generator (w_train_gen, w_val_gen, etc.)\n",
    "        soil_x: Soil features array\n",
    "        soil_y: Soil labels array (should match image labels)\n",
    "        batch_size: Batch size (should match image_gen batch_size)\n",
    "\n",
    "    Yields:\n",
    "        ([image_batch, weather_batch, soil_batch], label_batch)\n",
    "    \"\"\"\n",
    "    # Reset generators to ensure alignment\n",
    "    image_gen.reset()\n",
    "\n",
    "    # Convert soil data to match image generator ordering\n",
    "    # Get the file order from image generator\n",
    "    if hasattr(image_gen, 'filepaths'):\n",
    "        image_files = image_gen.filepaths\n",
    "    else:\n",
    "        image_files = image_gen.filenames\n",
    "\n",
    "    # Create index mapping for soil data alignment\n",
    "    soil_indices = []\n",
    "    for i in range(len(image_files)):\n",
    "        # Get the class index for this image\n",
    "        class_idx = image_gen.classes[i] if hasattr(image_gen, 'classes') else i // (len(image_files) // len(soil_x))\n",
    "        soil_indices.append(class_idx)\n",
    "\n",
    "    batch_idx = 0\n",
    "    total_samples = len(image_files)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Get image batch and labels\n",
    "            image_batch, label_batch = next(image_gen)\n",
    "\n",
    "            # Get corresponding weather batch\n",
    "            weather_batch, _ = next(weather_gen)\n",
    "\n",
    "            # Get corresponding soil batch\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = min(start_idx + batch_size, total_samples)\n",
    "\n",
    "            # Handle soil data batching\n",
    "            if start_idx < len(soil_x):\n",
    "                actual_end = min(end_idx, len(soil_x))\n",
    "                soil_batch = soil_x[start_idx:actual_end]\n",
    "\n",
    "                # Pad if necessary to match batch size\n",
    "                if len(soil_batch) < len(image_batch):\n",
    "                    padding_needed = len(image_batch) - len(soil_batch)\n",
    "                    padding = np.tile(soil_batch[-1:], (padding_needed, 1))\n",
    "                    soil_batch = np.vstack([soil_batch, padding])\n",
    "                elif len(soil_batch) > len(image_batch):\n",
    "                    soil_batch = soil_batch[:len(image_batch)]\n",
    "            else:\n",
    "                # Cycle back to beginning if we've exhausted soil data\n",
    "                soil_batch = soil_x[:len(image_batch)]\n",
    "\n",
    "            # Ensure all batches have the same length\n",
    "            min_batch_size = min(len(image_batch), len(weather_batch), len(soil_batch))\n",
    "\n",
    "            yield (\n",
    "                [\n",
    "                    image_batch[:min_batch_size],\n",
    "                    weather_batch[:min_batch_size],\n",
    "                    soil_batch[:min_batch_size]\n",
    "                ],\n",
    "                label_batch[:min_batch_size]\n",
    "            )\n",
    "\n",
    "            batch_idx += 1\n",
    "\n",
    "        except StopIteration:\n",
    "            # Reset all generators when image generator is exhausted\n",
    "            image_gen.reset()\n",
    "            batch_idx = 0\n",
    "            continue\n",
    "\n",
    "# Create the combined generators using your existing data\n",
    "print(\"Creating combined training generator...\")\n",
    "combined_train_gen = create_combined_generator(\n",
    "    train_gen, w_train_gen, x_train_soil, y_train_soil, batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(\"Creating combined validation generator...\")\n",
    "combined_val_gen = create_combined_generator(\n",
    "    validation_gen, w_val_gen, x_val_soil, y_val_soil, batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Test the combined generator\n",
    "print(\"\\nTesting combined generator...\")\n",
    "test_batch = next(combined_train_gen)\n",
    "images, weather, soil = test_batch[0]\n",
    "labels = test_batch[1]\n",
    "\n",
    "print(f\"Image batch shape: {images.shape}\")\n",
    "print(f\"Weather batch shape: {weather.shape}\")\n",
    "print(f\"Soil batch shape: {soil.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "# Keras-compatible combined data generator using tf.keras.utils.Sequence\n",
    "class CombinedDataSequence(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Keras-compatible combined data generator that inherits from tf.keras.utils.Sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_gen, weather_gen, soil_x, soil_y):\n",
    "        self.image_gen = image_gen\n",
    "        self.weather_gen = weather_gen\n",
    "        self.soil_x = soil_x\n",
    "        self.soil_y = soil_y\n",
    "        self.batch_size = image_gen.batch_size\n",
    "\n",
    "        # Calculate total number of batches and samples\n",
    "        self.n_samples = len(image_gen.classes) if hasattr(image_gen, 'classes') else image_gen.n\n",
    "        self.samples = self.n_samples  # Add samples attribute for Keras compatibility\n",
    "        self.total_batches = int(np.ceil(self.n_samples / self.batch_size))\n",
    "\n",
    "        # Pre-generate weather data for better performance\n",
    "        self._pregenerate_weather_data()\n",
    "\n",
    "    def _pregenerate_weather_data(self):\n",
    "        \"\"\"Pre-generate all weather data to avoid synchronization issues\"\"\"\n",
    "        print(\"Pre-generating weather data...\")\n",
    "        self.weather_data = []\n",
    "        temp_gen = iter(self.weather_gen)\n",
    "\n",
    "        for _ in range(self.total_batches):\n",
    "            try:\n",
    "                weather_batch, _ = next(temp_gen)\n",
    "                self.weather_data.append(weather_batch)\n",
    "            except StopIteration:\n",
    "                # If weather generator is exhausted, cycle back\n",
    "                temp_gen = iter(self.weather_gen)\n",
    "                weather_batch, _ = next(temp_gen)\n",
    "                self.weather_data.append(weather_batch)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches per epoch\"\"\"\n",
    "        return self.total_batches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get batch at index idx\"\"\"\n",
    "        # Get image batch using direct indexing approach\n",
    "        start_idx = idx * self.batch_size\n",
    "        end_idx = min(start_idx + self.batch_size, self.n_samples)\n",
    "\n",
    "        # Calculate which samples we need\n",
    "        sample_indices = list(range(start_idx, end_idx))\n",
    "\n",
    "        # Get image data by manually calling the generator's flow\n",
    "        if hasattr(self.image_gen, '_get_batches_of_transformed_samples'):\n",
    "            # Use internal method to get specific batch\n",
    "            batch_indices = [i % self.image_gen.n for i in sample_indices]\n",
    "            image_batch = np.array([\n",
    "                self.image_gen._get_batches_of_transformed_samples([i])[0][0]\n",
    "                for i in batch_indices\n",
    "            ])\n",
    "            label_batch = np.array([self.image_gen.classes[i] for i in batch_indices])\n",
    "            label_batch = tf.keras.utils.to_categorical(label_batch, num_classes=self.image_gen.num_classes)\n",
    "        else:\n",
    "            # Fallback: reset and skip to position\n",
    "            self.image_gen.reset()\n",
    "            target_batch = idx % len(self.image_gen)\n",
    "            for _ in range(target_batch):\n",
    "                next(self.image_gen)\n",
    "            image_batch, label_batch = next(self.image_gen)\n",
    "\n",
    "        # Get weather batch\n",
    "        weather_batch = self.weather_data[idx % len(self.weather_data)]\n",
    "\n",
    "        # Get soil batch\n",
    "        if start_idx < len(self.soil_x):\n",
    "            soil_batch = self.soil_x[start_idx:end_idx]\n",
    "        else:\n",
    "            # Cycle through soil data\n",
    "            cycle_start = start_idx % len(self.soil_x)\n",
    "            cycle_end = min(cycle_start + self.batch_size, len(self.soil_x))\n",
    "            soil_batch = self.soil_x[cycle_start:cycle_end]\n",
    "\n",
    "            # Handle wraparound if needed\n",
    "            if len(soil_batch) < self.batch_size:\n",
    "                remaining = self.batch_size - len(soil_batch)\n",
    "                additional = self.soil_x[:remaining]\n",
    "                soil_batch = np.vstack([soil_batch, additional])\n",
    "\n",
    "        # Ensure all batches have consistent size\n",
    "        actual_batch_size = min(len(image_batch), len(weather_batch), len(soil_batch))\n",
    "\n",
    "        # Return as dictionary format (recommended for multi-input models)\n",
    "        return (\n",
    "            {\n",
    "                'image_input': image_batch[:actual_batch_size],\n",
    "                'weather_input': weather_batch[:actual_batch_size],\n",
    "                'soil_input': soil_batch[:actual_batch_size]\n",
    "            },\n",
    "            label_batch[:actual_batch_size]\n",
    "        )\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Called at the end of each epoch\"\"\"\n",
    "        if hasattr(self.image_gen, 'on_epoch_end'):\n",
    "            self.image_gen.on_epoch_end()\n",
    "\n",
    "# Create Keras-compatible combined generators using your existing data\n",
    "print(\"Creating Keras-compatible combined generators...\")\n",
    "keras_train_gen = CombinedDataSequence(train_gen, w_train_gen, x_train_soil, y_train_soil)\n",
    "keras_val_gen = CombinedDataSequence(validation_gen, w_val_gen, x_val_soil, y_val_soil)\n",
    "\n",
    "# Test the Keras-compatible generator\n",
    "print(\"\\nTesting Keras-compatible generator...\")\n",
    "test_batch = keras_train_gen[0]  # Get first batch using indexing\n",
    "input_dict, labels = test_batch\n",
    "\n",
    "print(f\"Image batch shape: {input_dict['image_input'].shape}\")\n",
    "print(f\"Weather batch shape: {input_dict['weather_input'].shape}\")\n",
    "print(f\"Soil batch shape: {input_dict['soil_input'].shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"Total batches in training generator: {len(keras_train_gen)}\")\n",
    "\n",
    "# Now you can use these with model.fit()\n",
    "# fusion_model.fit(keras_train_gen, epochs=10, validation_data=keras_val_gen)\n",
    "\n",
    "# Helper function to create test generator when needed\n",
    "def create_combined_test_sequence():\n",
    "    \"\"\"Create combined test generator when needed\"\"\"\n",
    "    w_test_gen, _ = build_targeted_weather_generator(Test_gen, window_days=7)\n",
    "    return CombinedDataSequence(Test_gen, w_test_gen, x_test_soil, y_test_soil)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNzbMqf6CnaV45MAg7sh5T6",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
